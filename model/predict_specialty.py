import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F
import pandas as pd
import numpy as np

# âœ… ëª¨ë¸ ê²½ë¡œ ì„¤ì • (Google Drive ê¸°ì¤€)
MODEL_DIR = "/content/drive/MyDrive/kmbert_saved_model"

# âœ… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°
tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)
model.eval()  # í‰ê°€ ëª¨ë“œ

# âœ… í•™ìŠµ ì‹œ ì‚¬ìš©í–ˆë˜ LabelEncoderì˜ í´ë˜ìŠ¤ ëª©ë¡ (ìˆœì„œ ì¤‘ìš”)
label_classes = [
    'ê°€ì •ì˜í•™ê³¼', 'ê°ì—¼ë‚´ê³¼', 'ë‚´ë¶„ë¹„ëŒ€ì‚¬ë‚´ê³¼', 'ë¥˜ë§ˆí‹°ìŠ¤ë‚´ê³¼', 'ë§ˆì·¨í†µì¦ì˜í•™ê³¼', 'ë¹„ë‡¨ì˜í•™ê³¼', 'ì‚°ë¶€ì¸ê³¼',
    'ì„±í˜•ì™¸ê³¼', 'ì†Œì•„ì²­ì†Œë…„ê³¼', 'ì†Œí™”ê¸°ë‚´ê³¼', 'ìˆœí™˜ê¸°ë‚´ê³¼', 'ì‹ ê²½ê³¼', 'ì‹ ê²½ì™¸ê³¼', 'ì‹ ì¥ë‚´ê³¼', 'ì•ˆê³¼',
    'ì˜ìƒì˜í•™ê³¼', 'ì™¸ê³¼', 'ì‘ê¸‰ì˜í•™ê³¼', 'ì´ë¹„ì¸í›„ê³¼', 'ì¬í™œì˜í•™ê³¼', 'ì •ì‹ ê±´ê°•ì˜í•™ê³¼', 'ì •í˜•ì™¸ê³¼', 'ì¹˜ê³¼',
    'í”¼ë¶€ê³¼', 'í˜ˆì•¡ì¢…ì–‘ë‚´ê³¼', 'í˜¸í¡ê¸°ë‚´ê³¼', 'í‰ë¶€ì™¸ê³¼'
]

# âœ… ì˜ˆì¸¡ í•¨ìˆ˜
def predict_department(text, top_k=3):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = F.softmax(logits, dim=1).squeeze()

    # ìƒìœ„ Kê°œ ì¶”ì¶œ
    top_probs, top_indices = torch.topk(probs, k=top_k)
    top_probs = top_probs.numpy()
    top_labels = [label_classes[idx] for idx in top_indices]

    # ê²°ê³¼ ì¶œë ¥
    print(f"ğŸ“¨ ì…ë ¥ ë¬¸ì¥: {text}\n")
    print("ğŸ”® ì˜ˆì¸¡ ê²°ê³¼ (Top 3):")
    for i in range(top_k):
        print(f"{i+1}. {top_labels[i]:<10} â€” í™•ë¥ : {top_probs[i]*100:.2f}%")

    return list(zip(top_labels, top_probs))

# âœ… ì˜ˆì‹œ í…ŒìŠ¤íŠ¸
text = "ìš”ì¦˜ ì •ì‹ ì´ íë¦¿í•œë° í”¼ê³¤í•œ ê±¸ê¹Œìš”? ë‡Œê°€ ë¬¸ì œì¼ê¹Œìš”?"
predict_department(text)
